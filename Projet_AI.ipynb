{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mpl0NQlQ6_QQ"
   },
   "source": [
    "#1\n",
    "\n",
    "##1.1\n",
    "\n",
    "##1.2\n",
    "\n",
    "Softmax puisqu'il y a plus de 2 classes (Sigmoid ou Softmax)\n",
    "- Able to handle multiple classes \n",
    "- Useful for output neurons â€” typically Softmax is used only for the output layer, for neural networks that need to classify inputs into multiple categories.\n",
    "\n",
    "Relu :\n",
    "- ReLU activation function is widely used and is default choice as it yields better results.\n",
    "- ReLU function should only be used in the hidden layers.\n",
    "\n",
    "\n",
    "\n",
    "##1.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PVSRMd535tqv",
    "outputId": "1f388f44-fa1e-4149-c70c-ef5c1748cae9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/gdrive\n"
     ]
    }
   ],
   "source": [
    "#importing the drive to google colab\n",
    "from google.colab import drive\n",
    "#reading data from drive\n",
    "drive.mount('/content/gdrive', force_remount=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "InQYkaYNlpQa"
   },
   "outputs": [],
   "source": [
    "#Split the dataset\n",
    "#Train : 70%\n",
    "#Validation : 25%\n",
    "#Train & Validation to Train the model\n",
    "#Test : 5% to test the model at the end and deduce the Accuracy and the Confusion Matrix\n",
    "#In each folder we find 3 classes Labeled 0, 1 and 2 ; {1 : \"BEN\", 2 : \"CAN\", 0 : \"NOR\"}\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "class1 = {\"min\":1,\"max\":9215}\n",
    "class2 = {\"min\":9216,\"max\":10103}\n",
    "class3 = {\"min\":10104,\"max\":11218,}\n",
    "\n",
    "def ta9ssim(basePath,path,fileList):\n",
    "    if not os.path.isdir(path+\"/0\"):\n",
    "        os.makedirs(path+\"/0\")\n",
    "    if not os.path.isdir(path+\"/1\"):\n",
    "        os.makedirs(path+\"/1\")\n",
    "    if not os.path.isdir(path+\"/2\"):\n",
    "        os.makedirs(path+\"/2\")\n",
    "\n",
    "    for fichier in fileList:\n",
    "        if fichier.endswith(\".png\"):\n",
    "            x = int(fichier.split(\".\")[0])\n",
    "            if(class1[\"min\"] <= x <= class1[\"max\"]):\n",
    "                try:\n",
    "                    shutil.move(basePath+\"/\" + fichier , path+\"/0/\" + fichier)\n",
    "                except:\n",
    "                    pass\n",
    "            elif(class2[\"min\"] <= x <= class2[\"max\"]):\n",
    "                try:\n",
    "                    shutil.move(basePath+\"/\" + fichier , path+\"/1/\" + fichier)\n",
    "                except:\n",
    "                    pass\n",
    "            elif(class3[\"min\"] <= x <= class3[\"max\"]):\n",
    "                try:\n",
    "                    shutil.move(basePath+\"/\" + fichier , path+\"/2/\" + fichier)\n",
    "                except:\n",
    "                    pass\n",
    "\n",
    "pathLearn = \"/content/gdrive/MyDrive/ddsmROI\"\n",
    "pathTest = \"/content/gdrive/MyDrive/ddsmROI/ddtest\"\n",
    "pathValid = \"/content/gdrive/MyDrive/ddsmROI/ddvalid\"\n",
    "\n",
    "filelist=os.listdir(pathLearn)\n",
    "nbFiles = 11218\n",
    "validFiles = random.choices(filelist, k=int(nbFiles*0.25))\n",
    "filelist = [a for a in filelist if a not in validFiles]\n",
    "testFiles = random.choices(filelist, k=int(nbFiles*0.05))\n",
    "filelist = [a for a in filelist if a not in testFiles]\n",
    "learnFiles = filelist\n",
    "\n",
    "ta9ssim(pathLearn,pathTest,testFiles)\n",
    "ta9ssim(pathLearn,pathValid,validFiles)\n",
    "ta9ssim(pathLearn,pathLearn+\"/ddslearn\",learnFiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7k9vFqUHAfF1",
    "outputId": "f85e3b7f-b83b-4708-d7c4-3f0c95c343a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 123 files belonging to 3 classes.\n",
      "Found 2486 files belonging to 3 classes.\n",
      "Found 538 files belonging to 3 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "\n",
    "\n",
    "ds_train = image_dataset_from_directory(\n",
    "    'ddsmROI/ddtest2', #/train \n",
    "    image_size=[128, 128]\n",
    "\n",
    ")\n",
    "\n",
    "ds_valid = image_dataset_from_directory(\n",
    "    'ddsmROI/ddvalid', #/valid\n",
    "    image_size=[128, 128]\n",
    "   \n",
    ")\n",
    "\n",
    "ds_test = image_dataset_from_directory(\n",
    "    'ddsmROI/ddtest', #/test\n",
    "    image_size=[128, 128]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8PH_Y5LgjIFz"
   },
   "source": [
    "##kernel_size: \n",
    "- An integer or tuple/list of 2 integers, specifying the height and width of the 2D convolution window.\n",
    "\n",
    "- A common choice is to keep the kernel size at 3x3 or 5x5. The first convolutional layer is often kept larger.\n",
    "\n",
    "##padding: \n",
    "- one of \"valid\" or \"same\" (case-insensitive). \"valid\" means no padding. \"same\" results in padding with zeros evenly to the left/right or up/down of the input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "64Av5k2pAnex"
   },
   "outputs": [],
   "source": [
    "#Creating the Model\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "model = keras.Sequential([\n",
    "\n",
    "    # First Convolutional Block \n",
    "    layers.Conv2D(filters=32, kernel_size=5, activation=\"relu\", padding='same',\n",
    "                  # give the input dimensions in the first layer Here we are learning \n",
    "                  # a total of 32 filters and then we use Max Pooling to reduce the spatial dimensions of the output volume.\n",
    "                  # [height, width, color channels(RGB)]\n",
    "                  input_shape=[128,128,3]),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Second Convolutional Block\n",
    "    layers.Conv2D(filters=64, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Third Convolutional Block\n",
    "    layers.Conv2D(filters=128, kernel_size=3, activation=\"relu\", padding='same'),\n",
    "    layers.MaxPool2D(),\n",
    "\n",
    "    # Classifier Head\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(units=6, activation=\"relu\"),\n",
    "    layers.Dense(units=3, activation=\"softmax\"),\n",
    "])\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jTsFohZnAvHm",
    "outputId": "ef3fc794-5bb4-4273-f90b-f7a6a83e1919"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Total Number of Layers, including the input & the output\n",
    "len(model.layers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uRsaGbiBiF6k"
   },
   "source": [
    "#Use sparse categorical crossentropy when your classes are mutually exclusive (e.g. when each sample belongs exactly to one class) and categorical crossentropy when one sample can have multiple classes or labels are soft probabilities (like [0.5, 0.3, 0.2])."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 606
    },
    "id": "AuV8aQAjDjhF",
    "outputId": "13d964a6-1ee2-4365-dac0-521079d55c5c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "78/78 [==============================] - 39s 484ms/step - loss: 2.6795 - accuracy: 0.5286 - val_loss: 0.8504 - val_accuracy: 0.7955\n",
      "Epoch 2/4\n",
      "78/78 [==============================] - 41s 522ms/step - loss: 0.8345 - accuracy: 0.7792 - val_loss: 0.8228 - val_accuracy: 0.7881\n",
      "Epoch 3/4\n",
      "78/78 [==============================] - 37s 475ms/step - loss: 0.8166 - accuracy: 0.7767 - val_loss: 0.8116 - val_accuracy: 0.7937\n",
      "Epoch 4/4\n",
      "78/78 [==============================] - 39s 503ms/step - loss: 0.8058 - accuracy: 0.7808 - val_loss: 0.7980 - val_accuracy: 0.7993\n"
     ]
    }
   ],
   "source": [
    "#Training the model with the training set and the validation set (10 Epochs)\n",
    "import tensorflow as tf\n",
    "\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-06),\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "#verbose : shows the details of each epoch\n",
    "history = model.fit(\n",
    "    ds_valid,\n",
    "    validation_data=ds_test,\n",
    "    epochs=4,\n",
    "    verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TO8mroSFIH1V",
    "outputId": "accebe08-ebf8-4cb1-d36b-867f01731eae"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 [==============================] - 1s 90ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 2,\n",
       "       2, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 2, 0, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 1, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Testing the model with the testing Set\n",
    "import numpy as np\n",
    "\n",
    "pred = model.predict(ds_train)\n",
    "\n",
    "#argmax returns l'indice of the max value of the specified axe\n",
    "pred = np.argmax(pred, axis=1)\n",
    "\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_labels(model,test_ds):\n",
    "    # Initialize Lists\n",
    "    labels = []\n",
    "    pred_labels = []\n",
    "     # Make the test dataset an iterable object\n",
    "    test_ds = iter(test_ds)\n",
    "    # For each batch, append labels to both the true label array and predicted label array\n",
    "    for images, temp_labels in test_ds:\n",
    "        # Collect True Data Labels\n",
    "        temp_labels = tf.constant(temp_labels).numpy()\n",
    "        labels.extend(temp_labels)\n",
    "         # Collect Prediction Labels\n",
    "        prediction = model.predict(images,batch_size=32)\n",
    "        temp_pred_labels = prediction.argmax(axis=-1)\n",
    "        pred_labels.extend(temp_pred_labels)\n",
    "    return labels, pred_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 182ms/step\n",
      "1/1 [==============================] - 0s 120ms/step\n",
      "1/1 [==============================] - 0s 115ms/step\n",
      "1/1 [==============================] - 0s 169ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[48,  3,  0],\n",
       "       [33,  4,  7],\n",
       "       [24,  3,  1]], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn.metrics as metrics\n",
    "y_true_labels,ypred = predict_labels(model,ds_train)\n",
    "confusion_matrix = metrics.confusion_matrix(y_true=y_true_labels, y_pred=ypred)\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 113ms/step\n",
      "1/1 [==============================] - 0s 92ms/step\n",
      "1/1 [==============================] - 0s 93ms/step\n",
      "1/1 [==============================] - 0s 88ms/step\n",
      "Accuracy : 0.42276422764227645\n"
     ]
    }
   ],
   "source": [
    "def calculate_accuracy(labels, pred_labels):\n",
    "    TP = 0\n",
    "    TN = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    total = len(labels)\n",
    "     # Count for Confusion Matrix\n",
    "    for i in range(total):\n",
    "        if labels[i] == 1 and pred_labels[i] == 1:\n",
    "            TP += 1 # True Positive\n",
    "        elif labels[i] == 0 and pred_labels[i] == 0:\n",
    "            TN += 1 # True Negative\n",
    "        elif labels[i] == 0 and pred_labels[i] == 1:\n",
    "            FP += 1 # False Positive\n",
    "        elif labels[i] == 1 and pred_labels[i] == 0:\n",
    "            FN += 1 # False Negative\n",
    "        # Calculate Accuracy and return results\n",
    "    accuracy = (TN + TP)/total\n",
    "    return accuracy\n",
    "y_true_labels,ypred = predict_labels(model,ds_train)\n",
    "print(\"Accuracy : \"+str(calculate_accuracy(y_true_labels,ypred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "TVg_ZQ3MPnZ6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['BEN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'CAN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'BEN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'CAN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'CAN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'BEN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'BEN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'CAN',\n",
       " 'CAN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'CAN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'BEN',\n",
       " 'NOR',\n",
       " 'BEN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'CAN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'BEN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'BEN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'CAN',\n",
       " 'BEN',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'NOR',\n",
       " 'BEN']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = {1 : \"BEN\", 2 : \"CAN\", 0 : \"NOR\"}\n",
    "y_pred = [labels[k] for k in pred]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "jcZxdOB_b8o6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yosri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\outputs.py:196: UserWarning: Usage of gradio.outputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "C:\\Users\\yosri\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\gradio\\deprecation.py:40: UserWarning: The 'type' parameter has been deprecated. Use the Number component instead.\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7861\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7861/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 25ms/step\n",
      "[[9.7448051e-01 2.5335383e-02 1.8409510e-04]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "[[0.25298584 0.42014688 0.32686734]]\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[9.7448051e-01 2.5335383e-02 1.8409510e-04]]\n",
      "1/1 [==============================] - 0s 36ms/step\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr\n",
    "image=gr.inputs.Image(shape=(128,128))\n",
    "label=gr.outputs.Label(num_top_classes=8)\n",
    "labels = {1 : \"BEN / benign\", 2 : \"CAN / malignant\", 0 : \"NOR / normal\"}\n",
    "def predict_img(img):\n",
    "    print( model.predict(np.array([img,] )))\n",
    "    return labels[np.argmax(model.predict(np.array([img,] )))]\n",
    "\n",
    "gr.Interface(fn=predict_img,inputs=image,outputs=label,examples=[\"C:/Users/yosri/Desktop/New folder/ddsmROI/ddtest/0/38.png\", \"C:/Users/yosri/Desktop/New folder/ddsmROI/ddtest/0/91.png\"], allow_flagging=\"never\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
